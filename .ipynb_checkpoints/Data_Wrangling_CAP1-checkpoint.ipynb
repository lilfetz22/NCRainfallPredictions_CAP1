{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data on the website are not in one place, but spread out through several pages on the \n",
    "Southeast regional Climate Center website. Thus, my first step was not within python but gathering\n",
    "the data and placing it into a manageable format.\n",
    "\n",
    "North Carolina is separated into 3 regions Morehead City, Raleigh/Durham, and Wilmington. However, all of the weather stations that the SRCC uses in North Carolina are not all contained in these 3 regions. Several other regions that are placed under other states have regions that overlap into North Carolina, thus one must click on each of the regions within NC and all of the neighboring states regions in order to gather the data for all of the stations that are located in North Carolina. Then I had to go through and click on each location within the region, select the appropriate monthly rain data and copy and paste this data into an excel file as an individual sheet.\n",
    "\n",
    "In addition, my excel data file contains surrounding locations from these neighboring states that are close to North Carolina. We will use these points as exogenous datapoints to see any relationship between these locations and the locations within NC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "\n",
    "I imported the necessary modules and then load the excel spreadsheet that I used to collect all of the data from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:57:47.798035Z",
     "start_time": "2019-07-31T19:57:21.815381Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "import csv\n",
    "file = 'NC Monthly Precipitation Data.xlsx'\n",
    "NCdata = pd.ExcelFile(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2\n",
    "I needed to bring all of the separate sheets in excel together into a single dataframe. Thus, this function uses a for loop to parse out each sheet from the excel file. Once I had the sheet, all of the months were in separate columns. The function takes all of the months and places them next to the year then places the rainfall amounts for each month in the next column. The function merges the resulting dataframe into the blank dataframe on the year and the month columns with an outer join in order to catch all the data from both the original and merging dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:57:59.647647Z",
     "start_time": "2019-07-31T19:57:47.798035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>...</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "      <th>value_x</th>\n",
       "      <th>value_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>1864</td>\n",
       "      <td>Dec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952</th>\n",
       "      <td>1865</td>\n",
       "      <td>Dec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953</th>\n",
       "      <td>1866</td>\n",
       "      <td>Dec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>1867</td>\n",
       "      <td>Dec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1868</td>\n",
       "      <td>Dec</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year Month  value_x  value_y  value_x  value_y  value_x  value_y  \\\n",
       "1951  1864   Dec      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1952  1865   Dec      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1953  1866   Dec      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1954  1867   Dec      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1955  1868   Dec      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "      value_x  value_y  ...  value_x  value_y  value_x  value_y  value_x  \\\n",
       "1951      NaN      NaN  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "1952      NaN      NaN  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "1953      NaN      NaN  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "1954      NaN      NaN  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "1955      NaN      NaN  ...      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "      value_y  value_x  value_y  value_x  value_y  \n",
       "1951      NaN      NaN      NaN      NaN      NaN  \n",
       "1952      NaN      NaN      NaN      NaN      NaN  \n",
       "1953      NaN      NaN      NaN      NaN      NaN  \n",
       "1954      NaN      NaN      NaN      NaN      NaN  \n",
       "1955      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank = pd.DataFrame()\n",
    "def datachunks(s, e, df): #s and e stand for the beginning and end of the chunk you want\n",
    "    for i in range(s,e):\n",
    "        to_merge = NCdata.parse(i, skiprows=[0,1], usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12]) #first two rows in the data were titles\n",
    "        to_merge = to_merge.dropna() #removes two rows from the data that were labeled as NaN and not needed\n",
    "        to_merge = to_merge.set_index('Year') #set the index to year to remove the following 3 rows\n",
    "        to_merge = to_merge.drop(['Mean','Max', 'Min'])\n",
    "        to_merge = to_merge.reset_index() #resets the index so that the dataframe can be melted on Year\n",
    "        to_merge1 = pd.melt(to_merge, id_vars=['Year'], value_vars=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug',\n",
    "        'Sep','Oct','Nov','Dec'], var_name='Month') \n",
    "        to_merge1.iloc[:,2] = pd.to_numeric(to_merge1.iloc[:,2], errors = 'coerce')\n",
    "        if i == 0:\n",
    "            df = to_merge1\n",
    "        else:\n",
    "            df = pd.merge(df, to_merge1, on = ['Year','Month'], how = 'outer')\n",
    "    return df\n",
    "\n",
    "ncdata = datachunks(0,234, blank)\n",
    "ncdata.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3\n",
    "Column names to be placed on top of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:57:59.710144Z",
     "start_time": "2019-07-31T19:57:59.647647Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <th>Greensboro, NC</th>\n",
       "      <th>Fayetteville, NC</th>\n",
       "      <th>Albemarle, NC</th>\n",
       "      <th>Arcola, NC</th>\n",
       "      <th>Asheboro, NC</th>\n",
       "      <th>Burlington, NC</th>\n",
       "      <th>Carthage, NC</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGERSVILLE 1 NE, TN</th>\n",
       "      <th>SODDY DAISY-MOWBRAY MTN, TN</th>\n",
       "      <th>SPRING CITY, TN</th>\n",
       "      <th>TAZEWELL, TN</th>\n",
       "      <th>TOWNSEND 5S, TN</th>\n",
       "      <th>KING, NC</th>\n",
       "      <th>ABINGDON 3S, VA</th>\n",
       "      <th>WISE 1SE, VA</th>\n",
       "      <th>John Kerr Dam, VA</th>\n",
       "      <th>Emporia, VA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1887</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1888</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1889</td>\n",
       "      <td>Jan</td>\n",
       "      <td>6.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1890</td>\n",
       "      <td>Jan</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1891</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month  Raleigh, NC  Greensboro, NC  Fayetteville, NC  Albemarle, NC  \\\n",
       "0  1887   Jan         3.04             NaN               NaN            NaN   \n",
       "1  1888   Jan         3.98             NaN               NaN            NaN   \n",
       "2  1889   Jan         6.02             NaN               NaN            NaN   \n",
       "3  1890   Jan         0.83             NaN               NaN            NaN   \n",
       "4  1891   Jan         3.96             NaN               NaN            NaN   \n",
       "\n",
       "   Arcola, NC  Asheboro, NC  Burlington, NC  Carthage, NC  ...  \\\n",
       "0         NaN           NaN             NaN           NaN  ...   \n",
       "1         NaN           NaN             NaN           NaN  ...   \n",
       "2         NaN           NaN             NaN           NaN  ...   \n",
       "3         NaN           NaN             NaN           NaN  ...   \n",
       "4         NaN           NaN             NaN           NaN  ...   \n",
       "\n",
       "    ROGERSVILLE 1 NE, TN  SODDY DAISY-MOWBRAY MTN, TN  SPRING CITY, TN  \\\n",
       "0                    NaN                          NaN              NaN   \n",
       "1                    NaN                          NaN              NaN   \n",
       "2                   3.30                          NaN              NaN   \n",
       "3                   2.91                          NaN              NaN   \n",
       "4                    NaN                          NaN              NaN   \n",
       "\n",
       "   TAZEWELL, TN   TOWNSEND 5S, TN   KING, NC  ABINGDON 3S, VA  WISE 1SE, VA  \\\n",
       "0           NaN               NaN        NaN              NaN           NaN   \n",
       "1           NaN               NaN        NaN              NaN           NaN   \n",
       "2           NaN               NaN        NaN              NaN           NaN   \n",
       "3           NaN               NaN        NaN              NaN           NaN   \n",
       "4           NaN               NaN        NaN              NaN           NaN   \n",
       "\n",
       "   John Kerr Dam, VA  Emporia, VA  \n",
       "0                NaN          NaN  \n",
       "1                NaN          NaN  \n",
       "2                NaN          NaN  \n",
       "3                NaN          NaN  \n",
       "4                NaN          NaN  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['Year', 'Month']\n",
    "names = NCdata.sheet_names\n",
    "ncdata.columns = colnames + names\n",
    "ncdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4\n",
    "In order to sort the data based on the year and month I needed to first convert the columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:57:59.819516Z",
     "start_time": "2019-07-31T19:57:59.710144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month\n",
      "0  1887      1\n",
      "1  1888      1\n",
      "2  1889      1\n",
      "3  1890      1\n",
      "4  1891      1\n"
     ]
    }
   ],
   "source": [
    "ncdata[\"Month\"] = pd.to_datetime(ncdata.Month, format='%b', errors='coerce').dt.month\n",
    "ncdata[\"Year\"] = pd.to_datetime(ncdata.Year, format='%Y', errors='coerce').dt.year\n",
    "print(ncdata[['Year', 'Month']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:57:59.928888Z",
     "start_time": "2019-07-31T19:57:59.819516Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <th>Greensboro, NC</th>\n",
       "      <th>Fayetteville, NC</th>\n",
       "      <th>Albemarle, NC</th>\n",
       "      <th>Arcola, NC</th>\n",
       "      <th>Asheboro, NC</th>\n",
       "      <th>Burlington, NC</th>\n",
       "      <th>Carthage, NC</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGERSVILLE 1 NE, TN</th>\n",
       "      <th>SODDY DAISY-MOWBRAY MTN, TN</th>\n",
       "      <th>SPRING CITY, TN</th>\n",
       "      <th>TAZEWELL, TN</th>\n",
       "      <th>TOWNSEND 5S, TN</th>\n",
       "      <th>KING, NC</th>\n",
       "      <th>ABINGDON 3S, VA</th>\n",
       "      <th>WISE 1SE, VA</th>\n",
       "      <th>John Kerr Dam, VA</th>\n",
       "      <th>Emporia, VA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>3.43</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.77</td>\n",
       "      <td>4.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.62</td>\n",
       "      <td>7.10</td>\n",
       "      <td>8.27</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4.26</td>\n",
       "      <td>5.89</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>...</td>\n",
       "      <td>12.22</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14.42</td>\n",
       "      <td>14.67</td>\n",
       "      <td>9.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.22</td>\n",
       "      <td>10.51</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.77</td>\n",
       "      <td>6.98</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>6.36</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.89</td>\n",
       "      <td>6.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.55</td>\n",
       "      <td>7.75</td>\n",
       "      <td>6.29</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.97</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.34</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.47</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Raleigh, NC  Greensboro, NC  Fayetteville, NC  \\\n",
       "132   2019      1         3.43            4.01              2.77   \n",
       "265   2019      2         4.26            5.89              2.05   \n",
       "398   2019      3         3.17            3.19              2.66   \n",
       "531   2019      4         6.36            4.16              4.89   \n",
       "664   2019      5          NaN             NaN               NaN   \n",
       "797   2019      6          NaN             NaN               NaN   \n",
       "930   2019      7          NaN             NaN               NaN   \n",
       "1063  2019      8          NaN             NaN               NaN   \n",
       "1196  2019      9          NaN             NaN               NaN   \n",
       "1329  2019     10          NaN             NaN               NaN   \n",
       "1462  2019     11          NaN             NaN               NaN   \n",
       "1595  2019     12          NaN             NaN               NaN   \n",
       "\n",
       "      Albemarle, NC  Arcola, NC  Asheboro, NC  Burlington, NC  Carthage, NC  \\\n",
       "132            4.60         NaN          4.43             NaN           NaN   \n",
       "265            2.97         NaN          5.86             NaN          4.67   \n",
       "398            2.62         NaN          3.86             NaN           NaN   \n",
       "531            6.60         NaN          5.42             NaN           NaN   \n",
       "664             NaN         NaN           NaN             NaN           NaN   \n",
       "797             NaN         NaN           NaN             NaN           NaN   \n",
       "930             NaN         NaN           NaN             NaN           NaN   \n",
       "1063            NaN         NaN           NaN             NaN           NaN   \n",
       "1196            NaN         NaN           NaN             NaN           NaN   \n",
       "1329            NaN         NaN           NaN             NaN           NaN   \n",
       "1462            NaN         NaN           NaN             NaN           NaN   \n",
       "1595            NaN         NaN           NaN             NaN           NaN   \n",
       "\n",
       "      ...   ROGERSVILLE 1 NE, TN  SODDY DAISY-MOWBRAY MTN, TN  \\\n",
       "132   ...                   4.62                         7.10   \n",
       "265   ...                  12.22                        10.00   \n",
       "398   ...                   4.74                         4.77   \n",
       "531   ...                   5.55                         7.75   \n",
       "664   ...                   4.82                          NaN   \n",
       "797   ...                    NaN                          NaN   \n",
       "930   ...                    NaN                          NaN   \n",
       "1063  ...                    NaN                          NaN   \n",
       "1196  ...                    NaN                          NaN   \n",
       "1329  ...                    NaN                          NaN   \n",
       "1462  ...                    NaN                          NaN   \n",
       "1595  ...                    NaN                          NaN   \n",
       "\n",
       "      SPRING CITY, TN  TAZEWELL, TN   TOWNSEND 5S, TN   KING, NC  \\\n",
       "132              8.27          5.54              5.32       4.65   \n",
       "265             14.42         14.67              9.64       6.00   \n",
       "398              6.98          4.94              5.51       2.35   \n",
       "531              6.29          3.58              7.97       4.39   \n",
       "664              4.34          5.10              5.47       2.22   \n",
       "797               NaN           NaN               NaN        NaN   \n",
       "930               NaN           NaN               NaN        NaN   \n",
       "1063              NaN           NaN               NaN        NaN   \n",
       "1196              NaN           NaN               NaN        NaN   \n",
       "1329              NaN           NaN               NaN        NaN   \n",
       "1462              NaN           NaN               NaN        NaN   \n",
       "1595              NaN           NaN               NaN        NaN   \n",
       "\n",
       "      ABINGDON 3S, VA  WISE 1SE, VA  John Kerr Dam, VA  Emporia, VA  \n",
       "132              5.10          4.17               3.38          NaN  \n",
       "265              9.22         10.51               5.70         5.61  \n",
       "398              3.13          3.78               3.63         3.90  \n",
       "531              4.52          5.28               3.23         3.98  \n",
       "664              2.82          4.39                NaN         1.23  \n",
       "797               NaN           NaN                NaN          NaN  \n",
       "930               NaN           NaN                NaN          NaN  \n",
       "1063              NaN           NaN                NaN          NaN  \n",
       "1196              NaN           NaN                NaN          NaN  \n",
       "1329              NaN           NaN                NaN          NaN  \n",
       "1462              NaN           NaN                NaN          NaN  \n",
       "1595              NaN           NaN                NaN          NaN  \n",
       "\n",
       "[12 rows x 236 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this sorts the data based on year then month\n",
    "ncdata_sorted = ncdata.sort_values(['Year','Month'])\n",
    "ncdata_sorted.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Instead of separate columns for year and month the following code creates a single Date column and sets it as the index. The index is a string because datetime does not allow for dates without a day; however, having a day listed in the datetime would not be reasonable in this dataset because these are monthly totals of rainfall not occurring on a single day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:00.678861Z",
     "start_time": "2019-07-31T19:57:59.928888Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <th>Greensboro, NC</th>\n",
       "      <th>Fayetteville, NC</th>\n",
       "      <th>Albemarle, NC</th>\n",
       "      <th>Arcola, NC</th>\n",
       "      <th>Asheboro, NC</th>\n",
       "      <th>Burlington, NC</th>\n",
       "      <th>Carthage, NC</th>\n",
       "      <th>Chapel Hill, NC</th>\n",
       "      <th>Clayton, NC</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGERSVILLE 1 NE, TN</th>\n",
       "      <th>SODDY DAISY-MOWBRAY MTN, TN</th>\n",
       "      <th>SPRING CITY, TN</th>\n",
       "      <th>TAZEWELL, TN</th>\n",
       "      <th>TOWNSEND 5S, TN</th>\n",
       "      <th>KING, NC</th>\n",
       "      <th>ABINGDON 3S, VA</th>\n",
       "      <th>WISE 1SE, VA</th>\n",
       "      <th>John Kerr Dam, VA</th>\n",
       "      <th>Emporia, VA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-1857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-1857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-1857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-1857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-1857</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Raleigh, NC  Greensboro, NC  Fayetteville, NC  Albemarle, NC  \\\n",
       "Date                                                                   \n",
       "1-1857          NaN             NaN               NaN            NaN   \n",
       "2-1857          NaN             NaN               NaN            NaN   \n",
       "3-1857          NaN             NaN               NaN            NaN   \n",
       "4-1857          NaN             NaN               NaN            NaN   \n",
       "5-1857          NaN             NaN               NaN            NaN   \n",
       "\n",
       "        Arcola, NC  Asheboro, NC  Burlington, NC  Carthage, NC  \\\n",
       "Date                                                             \n",
       "1-1857         NaN           NaN             NaN           NaN   \n",
       "2-1857         NaN           NaN             NaN           NaN   \n",
       "3-1857         NaN           NaN             NaN           NaN   \n",
       "4-1857         NaN           NaN             NaN           NaN   \n",
       "5-1857         NaN           NaN             NaN           NaN   \n",
       "\n",
       "        Chapel Hill, NC  Clayton, NC  ...   ROGERSVILLE 1 NE, TN  \\\n",
       "Date                                  ...                          \n",
       "1-1857              NaN          NaN  ...                    NaN   \n",
       "2-1857              NaN          NaN  ...                    NaN   \n",
       "3-1857              NaN          NaN  ...                    NaN   \n",
       "4-1857              NaN          NaN  ...                    NaN   \n",
       "5-1857              NaN          NaN  ...                    NaN   \n",
       "\n",
       "        SODDY DAISY-MOWBRAY MTN, TN  SPRING CITY, TN  TAZEWELL, TN  \\\n",
       "Date                                                                 \n",
       "1-1857                          NaN              NaN           NaN   \n",
       "2-1857                          NaN              NaN           NaN   \n",
       "3-1857                          NaN              NaN           NaN   \n",
       "4-1857                          NaN              NaN           NaN   \n",
       "5-1857                          NaN              NaN           NaN   \n",
       "\n",
       "         TOWNSEND 5S, TN   KING, NC  ABINGDON 3S, VA  WISE 1SE, VA  \\\n",
       "Date                                                                 \n",
       "1-1857               NaN        NaN              NaN           NaN   \n",
       "2-1857               NaN        NaN              NaN           NaN   \n",
       "3-1857               NaN        NaN              NaN           NaN   \n",
       "4-1857               NaN        NaN              NaN           NaN   \n",
       "5-1857               NaN        NaN              NaN           NaN   \n",
       "\n",
       "        John Kerr Dam, VA  Emporia, VA  \n",
       "Date                                    \n",
       "1-1857                NaN          NaN  \n",
       "2-1857                NaN          NaN  \n",
       "3-1857                NaN          NaN  \n",
       "4-1857                NaN          NaN  \n",
       "5-1857                NaN          NaN  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncdata_sorted['Year'] = ncdata_sorted.Year.apply(str)\n",
    "ncdata_sorted['Month'] = ncdata_sorted.Month.apply(str)\n",
    "ncdata_sorted['Date'] = ncdata_sorted['Month'] + '-' + ncdata_sorted['Year']\n",
    "ncdata1 = ncdata_sorted.set_index('Date')\n",
    "ncdata1 = ncdata1.drop(['Year', 'Month'], axis=1)\n",
    "ncdata1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6 - removing impossible data\n",
    "I gathered this data in May 2019; thus, it was impossible to have any totals from months that had not happened yet; therefore, I removed them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:00.772609Z",
     "start_time": "2019-07-31T19:58:00.678861Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <th>Greensboro, NC</th>\n",
       "      <th>Fayetteville, NC</th>\n",
       "      <th>Albemarle, NC</th>\n",
       "      <th>Arcola, NC</th>\n",
       "      <th>Asheboro, NC</th>\n",
       "      <th>Burlington, NC</th>\n",
       "      <th>Carthage, NC</th>\n",
       "      <th>Chapel Hill, NC</th>\n",
       "      <th>Clayton, NC</th>\n",
       "      <th>...</th>\n",
       "      <th>ROGERSVILLE 1 NE, TN</th>\n",
       "      <th>SODDY DAISY-MOWBRAY MTN, TN</th>\n",
       "      <th>SPRING CITY, TN</th>\n",
       "      <th>TAZEWELL, TN</th>\n",
       "      <th>TOWNSEND 5S, TN</th>\n",
       "      <th>KING, NC</th>\n",
       "      <th>ABINGDON 3S, VA</th>\n",
       "      <th>WISE 1SE, VA</th>\n",
       "      <th>John Kerr Dam, VA</th>\n",
       "      <th>Emporia, VA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5-2018</th>\n",
       "      <td>5.12</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.23</td>\n",
       "      <td>7.40</td>\n",
       "      <td>3.55</td>\n",
       "      <td>5.94</td>\n",
       "      <td>4.27</td>\n",
       "      <td>9.85</td>\n",
       "      <td>4.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>8.03</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6-2018</th>\n",
       "      <td>1.98</td>\n",
       "      <td>2.53</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.55</td>\n",
       "      <td>...</td>\n",
       "      <td>5.26</td>\n",
       "      <td>7.35</td>\n",
       "      <td>9.26</td>\n",
       "      <td>7.22</td>\n",
       "      <td>5.27</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.39</td>\n",
       "      <td>6.51</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7-2018</th>\n",
       "      <td>4.92</td>\n",
       "      <td>6.04</td>\n",
       "      <td>6.36</td>\n",
       "      <td>5.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.35</td>\n",
       "      <td>7.39</td>\n",
       "      <td>3.10</td>\n",
       "      <td>4.19</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.37</td>\n",
       "      <td>5.08</td>\n",
       "      <td>5.63</td>\n",
       "      <td>5.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8-2018</th>\n",
       "      <td>6.62</td>\n",
       "      <td>6.97</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.36</td>\n",
       "      <td>...</td>\n",
       "      <td>4.85</td>\n",
       "      <td>6.15</td>\n",
       "      <td>7.39</td>\n",
       "      <td>5.51</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.72</td>\n",
       "      <td>9.23</td>\n",
       "      <td>3.46</td>\n",
       "      <td>4.64</td>\n",
       "      <td>6.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9-2018</th>\n",
       "      <td>7.97</td>\n",
       "      <td>9.17</td>\n",
       "      <td>15.54</td>\n",
       "      <td>12.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.65</td>\n",
       "      <td>...</td>\n",
       "      <td>7.18</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.61</td>\n",
       "      <td>4.61</td>\n",
       "      <td>7.61</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.03</td>\n",
       "      <td>6.70</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-2018</th>\n",
       "      <td>4.58</td>\n",
       "      <td>7.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>6.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.93</td>\n",
       "      <td>...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.63</td>\n",
       "      <td>4.18</td>\n",
       "      <td>7.40</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.30</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-2018</th>\n",
       "      <td>7.10</td>\n",
       "      <td>6.46</td>\n",
       "      <td>5.31</td>\n",
       "      <td>8.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.29</td>\n",
       "      <td>...</td>\n",
       "      <td>5.88</td>\n",
       "      <td>8.10</td>\n",
       "      <td>7.62</td>\n",
       "      <td>5.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.21</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-2018</th>\n",
       "      <td>6.23</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.24</td>\n",
       "      <td>...</td>\n",
       "      <td>6.72</td>\n",
       "      <td>7.11</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.04</td>\n",
       "      <td>8.75</td>\n",
       "      <td>6.54</td>\n",
       "      <td>5.12</td>\n",
       "      <td>6.53</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-2019</th>\n",
       "      <td>3.43</td>\n",
       "      <td>4.01</td>\n",
       "      <td>2.77</td>\n",
       "      <td>4.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.74</td>\n",
       "      <td>...</td>\n",
       "      <td>4.62</td>\n",
       "      <td>7.10</td>\n",
       "      <td>8.27</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.65</td>\n",
       "      <td>5.10</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-2019</th>\n",
       "      <td>4.26</td>\n",
       "      <td>5.89</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.11</td>\n",
       "      <td>...</td>\n",
       "      <td>12.22</td>\n",
       "      <td>10.00</td>\n",
       "      <td>14.42</td>\n",
       "      <td>14.67</td>\n",
       "      <td>9.64</td>\n",
       "      <td>6.00</td>\n",
       "      <td>9.22</td>\n",
       "      <td>10.51</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-2019</th>\n",
       "      <td>3.17</td>\n",
       "      <td>3.19</td>\n",
       "      <td>2.66</td>\n",
       "      <td>2.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.74</td>\n",
       "      <td>4.77</td>\n",
       "      <td>6.98</td>\n",
       "      <td>4.94</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.35</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-2019</th>\n",
       "      <td>6.36</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.89</td>\n",
       "      <td>6.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.47</td>\n",
       "      <td>...</td>\n",
       "      <td>5.55</td>\n",
       "      <td>7.75</td>\n",
       "      <td>6.29</td>\n",
       "      <td>3.58</td>\n",
       "      <td>7.97</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Raleigh, NC  Greensboro, NC  Fayetteville, NC  Albemarle, NC  \\\n",
       "Date                                                                    \n",
       "5-2018          5.12            3.77              2.68           3.37   \n",
       "6-2018          1.98            2.53              4.31           3.11   \n",
       "7-2018          4.92            6.04              6.36           5.83   \n",
       "8-2018          6.62            6.97              5.75           5.37   \n",
       "9-2018          7.97            9.17             15.54          12.83   \n",
       "10-2018         4.58            7.22              2.22           6.87   \n",
       "11-2018         7.10            6.46              5.31           8.22   \n",
       "12-2018         6.23            6.99              6.00           8.43   \n",
       "1-2019          3.43            4.01              2.77           4.60   \n",
       "2-2019          4.26            5.89              2.05           2.97   \n",
       "3-2019          3.17            3.19              2.66           2.62   \n",
       "4-2019          6.36            4.16              4.89           6.60   \n",
       "\n",
       "         Arcola, NC  Asheboro, NC  Burlington, NC  Carthage, NC  \\\n",
       "Date                                                              \n",
       "5-2018          NaN          7.56             NaN          2.98   \n",
       "6-2018          NaN          1.79             NaN           NaN   \n",
       "7-2018          NaN          2.69             NaN           NaN   \n",
       "8-2018          NaN          9.26             NaN          9.43   \n",
       "9-2018          NaN         14.11             NaN           NaN   \n",
       "10-2018         NaN          5.24             NaN           NaN   \n",
       "11-2018         NaN          9.18             NaN           NaN   \n",
       "12-2018         NaN          6.41             NaN           NaN   \n",
       "1-2019          NaN          4.43             NaN           NaN   \n",
       "2-2019          NaN          5.86             NaN          4.67   \n",
       "3-2019          NaN          3.86             NaN           NaN   \n",
       "4-2019          NaN          5.42             NaN           NaN   \n",
       "\n",
       "         Chapel Hill, NC  Clayton, NC  ...   ROGERSVILLE 1 NE, TN  \\\n",
       "Date                                   ...                          \n",
       "5-2018               NaN         4.05  ...                   5.23   \n",
       "6-2018               NaN         3.55  ...                   5.26   \n",
       "7-2018               NaN         7.25  ...                   2.13   \n",
       "8-2018               NaN         7.36  ...                   4.85   \n",
       "9-2018               NaN        10.65  ...                   7.18   \n",
       "10-2018              NaN         3.93  ...                   4.05   \n",
       "11-2018              NaN         6.29  ...                   5.88   \n",
       "12-2018              NaN         9.24  ...                   6.72   \n",
       "1-2019               NaN         4.74  ...                   4.62   \n",
       "2-2019               NaN         5.11  ...                  12.22   \n",
       "3-2019               NaN          NaN  ...                   4.74   \n",
       "4-2019               NaN         8.47  ...                   5.55   \n",
       "\n",
       "         SODDY DAISY-MOWBRAY MTN, TN  SPRING CITY, TN  TAZEWELL, TN  \\\n",
       "Date                                                                  \n",
       "5-2018                          7.40             3.55          5.94   \n",
       "6-2018                          7.35             9.26          7.22   \n",
       "7-2018                          3.35             7.39          3.10   \n",
       "8-2018                          6.15             7.39          5.51   \n",
       "9-2018                         11.25            11.61          4.61   \n",
       "10-2018                         2.80             2.89          2.63   \n",
       "11-2018                         8.10             7.62          5.17   \n",
       "12-2018                         7.11             9.49          7.04   \n",
       "1-2019                          7.10             8.27          5.54   \n",
       "2-2019                         10.00            14.42         14.67   \n",
       "3-2019                          4.77             6.98          4.94   \n",
       "4-2019                          7.75             6.29          3.58   \n",
       "\n",
       "          TOWNSEND 5S, TN   KING, NC  ABINGDON 3S, VA  WISE 1SE, VA  \\\n",
       "Date                                                                  \n",
       "5-2018               4.27       9.85             4.10          5.39   \n",
       "6-2018               5.27       2.74             3.39          6.51   \n",
       "7-2018               4.19       2.29             3.37          5.08   \n",
       "8-2018               6.98       6.72             9.23          3.46   \n",
       "9-2018               7.61       7.00             7.03          6.70   \n",
       "10-2018              4.18       7.40             3.58          3.30   \n",
       "11-2018               NaN       5.83             5.25          5.21   \n",
       "12-2018              8.75       6.54             5.12          6.53   \n",
       "1-2019               5.32       4.65             5.10          4.17   \n",
       "2-2019               9.64       6.00             9.22         10.51   \n",
       "3-2019               5.51       2.35             3.13          3.78   \n",
       "4-2019               7.97       4.39             4.52          5.28   \n",
       "\n",
       "         John Kerr Dam, VA  Emporia, VA  \n",
       "Date                                     \n",
       "5-2018                8.03         3.55  \n",
       "6-2018                5.82         5.03  \n",
       "7-2018                5.63         5.23  \n",
       "8-2018                4.64         6.39  \n",
       "9-2018                4.70         4.98  \n",
       "10-2018               5.05         4.49  \n",
       "11-2018               6.61         6.29  \n",
       "12-2018               4.85         4.44  \n",
       "1-2019                3.38          NaN  \n",
       "2-2019                5.70         5.61  \n",
       "3-2019                3.63         3.90  \n",
       "4-2019                3.23         3.98  \n",
       "\n",
       "[12 rows x 234 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncdata1 = ncdata1.drop(['5-2019', '6-2019', '7-2019', '8-2019','9-2019','10-2019','11-2019','12-2019'], axis=0)\n",
    "ncdata1.tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7\n",
    "There was a lot of missing data from several locations. Due to this I created the following for loop in order to see which rows (corresponding to a single month) had at least 70% of data. Since the function len() counts missing data while the method .count() does not, I used these two functions to figure out the percentage that each row has and made it a column in the dataframe called 'percent_number'\n",
    "\n",
    "I found that from January 1956-present all had data from at least 70% of the locations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:01.640998Z",
     "start_time": "2019-07-31T19:58:00.772609Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "8-1980     80.341880\n",
       "10-1980    80.341880\n",
       "11-1980    80.341880\n",
       "1-1981     80.769231\n",
       "2-1981     80.341880\n",
       "3-1981     81.623932\n",
       "4-1981     80.769231\n",
       "5-1981     80.341880\n",
       "6-1981     80.341880\n",
       "7-1981     80.341880\n",
       "9-1981     81.196581\n",
       "10-1981    80.341880\n",
       "4-1982     81.196581\n",
       "7-1982     81.196581\n",
       "9-1982     80.769231\n",
       "10-1982    80.769231\n",
       "11-1982    81.196581\n",
       "2-1983     80.769231\n",
       "3-1983     80.341880\n",
       "4-1983     80.341880\n",
       "Name: percent_number, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lop = []\n",
    "for i in ncdata1.index:\n",
    "    l = len(ncdata1.loc[i])\n",
    "    c = ncdata1.loc[i].count()\n",
    "    percent = (c/l)*100\n",
    "    if i == 0:\n",
    "        lop = [percent]\n",
    "    else:\n",
    "        lop = lop + [percent]\n",
    "ncdata1['percent_number'] = lop\n",
    "ncdata1.percent_number[ncdata1.percent_number >= 80].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8\n",
    "Since I had the Date column as my index and I didn't want to remove it, I created a new index row called row_number. I used the row number to figure out which row 1-1956 was located at in order to create the dataframe that includes only data from 1-1956-present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:01.672242Z",
     "start_time": "2019-07-31T19:58:01.640998Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1476"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl = [i for i in range(1948)]\n",
    "ncdata1['row_number'] = nl \n",
    "ncdata1.row_number.loc['1-1980'] # provides the row which Jan 1956 is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:01.750371Z",
     "start_time": "2019-07-31T19:58:01.672242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <th>Greensboro, NC</th>\n",
       "      <th>Fayetteville, NC</th>\n",
       "      <th>Albemarle, NC</th>\n",
       "      <th>Arcola, NC</th>\n",
       "      <th>Asheboro, NC</th>\n",
       "      <th>Burlington, NC</th>\n",
       "      <th>Carthage, NC</th>\n",
       "      <th>Chapel Hill, NC</th>\n",
       "      <th>Clayton, NC</th>\n",
       "      <th>...</th>\n",
       "      <th>SPRING CITY, TN</th>\n",
       "      <th>TAZEWELL, TN</th>\n",
       "      <th>TOWNSEND 5S, TN</th>\n",
       "      <th>KING, NC</th>\n",
       "      <th>ABINGDON 3S, VA</th>\n",
       "      <th>WISE 1SE, VA</th>\n",
       "      <th>John Kerr Dam, VA</th>\n",
       "      <th>Emporia, VA</th>\n",
       "      <th>percent_number</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1-1980</th>\n",
       "      <td>4.39</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.77</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3.57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.76</td>\n",
       "      <td>5.34</td>\n",
       "      <td>75.213675</td>\n",
       "      <td>1476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2-1980</th>\n",
       "      <td>1.91</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.27</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-1980</th>\n",
       "      <td>5.87</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.93</td>\n",
       "      <td>11.39</td>\n",
       "      <td>5.59</td>\n",
       "      <td>6.33</td>\n",
       "      <td>5.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.28</td>\n",
       "      <td>5.19</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.84</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.24</td>\n",
       "      <td>74.786325</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-1980</th>\n",
       "      <td>1.97</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.94</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.51</td>\n",
       "      <td>4.03</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.73</td>\n",
       "      <td>79.487179</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5-1980</th>\n",
       "      <td>2.33</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.77</td>\n",
       "      <td>5.14</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.30</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.66</td>\n",
       "      <td>78.205128</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Raleigh, NC  Greensboro, NC  Fayetteville, NC  Albemarle, NC  \\\n",
       "Date                                                                   \n",
       "1-1980         4.39            4.00              3.77           4.87   \n",
       "2-1980         1.91            1.77              1.77           0.84   \n",
       "3-1980         5.87            5.04              5.93          11.39   \n",
       "4-1980         1.97            3.24              3.61           3.49   \n",
       "5-1980         2.33            3.23              1.77           5.14   \n",
       "\n",
       "        Arcola, NC  Asheboro, NC  Burlington, NC  Carthage, NC  \\\n",
       "Date                                                             \n",
       "1-1980        4.01          4.65            4.43          4.95   \n",
       "2-1980        1.29          1.55            1.82          1.21   \n",
       "3-1980        5.59          6.33            5.69           NaN   \n",
       "4-1980        1.94          1.86            2.79           NaN   \n",
       "5-1980        2.24          4.36            3.86           NaN   \n",
       "\n",
       "        Chapel Hill, NC  Clayton, NC  ...  SPRING CITY, TN  TAZEWELL, TN  \\\n",
       "Date                                  ...                                  \n",
       "1-1980             4.08         3.57  ...              NaN          6.06   \n",
       "2-1980             2.05         2.03  ...              NaN          2.43   \n",
       "3-1980             6.28         5.19  ...              NaN          7.51   \n",
       "4-1980             2.32         2.94  ...              NaN          3.37   \n",
       "5-1980             4.50         2.30  ...              NaN          3.79   \n",
       "\n",
       "         TOWNSEND 5S, TN   KING, NC  ABINGDON 3S, VA  WISE 1SE, VA  \\\n",
       "Date                                                                 \n",
       "1-1980               NaN        NaN             4.22           NaN   \n",
       "2-1980               NaN        NaN             1.48          1.15   \n",
       "3-1980               NaN        NaN             5.84          4.32   \n",
       "4-1980               NaN        NaN             3.51          4.03   \n",
       "5-1980               NaN        NaN             4.08          2.88   \n",
       "\n",
       "        John Kerr Dam, VA  Emporia, VA  percent_number  row_number  \n",
       "Date                                                                \n",
       "1-1980               4.76         5.34       75.213675        1476  \n",
       "2-1980               1.45         1.27       77.777778        1477  \n",
       "3-1980               4.02         3.24       74.786325        1478  \n",
       "4-1980               3.24         2.73       79.487179        1479  \n",
       "5-1980               4.01         4.66       78.205128        1480  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncdata_80 = ncdata1[ncdata1.row_number >= 1476]\n",
    "ncdata_80.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:01.781611Z",
     "start_time": "2019-07-31T19:58:01.750371Z"
    }
   },
   "outputs": [],
   "source": [
    "#this drops the percent number column that is no longer needed.\n",
    "ncdata_80 = ncdata_80.drop(['percent_number'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9\n",
    "The dataset also has some missing data from when the location began gathering data to the present. For example, even though Raleigh, NC has been gathering data from 1-1956 until the present there was one month in October of 2000 where the monthly total was not recorded. Thus the following function fills in missing data that are contained within the locations. This function finds the months with missing data and fills them in by averaging the rainfall totals from the previous year, previous month and next month. If the any of these points are not available either the function uses the data from two years prior, two months prior, or two months after. If just one of these is not available it ignores the NaN and averages the other two, otherwise it keeps the datapoint as NaN. Thus, this function does not get rid of all missing values, but fills in the missing values as long as there is adequate data to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T19:58:01.828485Z",
     "start_time": "2019-07-31T19:58:01.781611Z"
    }
   },
   "outputs": [],
   "source": [
    "def missingfill(df, column):\n",
    "    missing = df.index[df[column].isnull()]\n",
    "    if len(missing) > 0:\n",
    "        for n in missing:\n",
    "            moth = df.loc[n].row_number # finds the row index for the missing data point\n",
    "            if ((moth >= 1488) & (moth <= 1945)): #must be a year after 1-1956 (rownumber=1188) otherwise it is impossible to have the previous year's data to gather from\n",
    "                ly = moth - 12 #the previous year's row number\n",
    "                lyrd = df[[column]][df['row_number'] == ly] # the previous year's rainfall amount as a dataframe\n",
    "                lyrd1 = lyrd[column][0] #separates the value of the previous year's dataframe to just the rainfall amount\n",
    "                lm = moth - 1 # the next 6 lines perform the same as the previous 3 except for previous month and following month\n",
    "                lmrd = df[[column]][df['row_number'] == lm]\n",
    "                lmrd1 = lmrd[column][0]\n",
    "                nm = moth + 1\n",
    "                nmrd = df[[column]][df['row_number'] == nm]\n",
    "                nmrd1 = nmrd[column][0]\n",
    "                if ((math.isnan(lyrd1)) & (moth >= 1500)): # if the previous year was not available, go back 2 years\n",
    "                    twy = moth - 24\n",
    "                    twyrd = df[[column]][df['row_number'] == twy]\n",
    "                    lyrd1 = twyrd[column][0]\n",
    "                if (math.isnan(lmrd1)): #if the previous month was not available, go back 2 months\n",
    "                    lm = moth - 2\n",
    "                    lmrd = df[[column]][df['row_number'] == lm]\n",
    "                    lmrd1 = lmrd[column][0]\n",
    "                if (math.isnan(nmrd1)): #if the next month was not available, go forward 2 months\n",
    "                    nm = moth + 2\n",
    "                    nmrd = df[[column]][df['row_number'] == nm]\n",
    "                    nmrd1 = nmrd[column][0]\n",
    "                newpoint = np.nanmean([lyrd1,lmrd1,nmrd1]) #finds the average of the 3 values \n",
    "                df.loc[n,column] = newpoint #places the value into the missing data slot\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10 \n",
    "performs the function defined in the previous cell and applies the function to every column. The runtime warning just means that np.nanmean has only nan values and thus is returning a nan value again, which is fine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.400352Z",
     "start_time": "2019-07-31T19:58:01.828485Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "for i in ncdata_80.columns:\n",
    "    ncdata_80 = missingfill(ncdata_80, i)\n",
    "ncdata_80.info()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "Drop the row_number column since it is no longer needed, and make a csv file from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.556718Z",
     "start_time": "2019-07-31T20:01:41.400352Z"
    }
   },
   "outputs": [],
   "source": [
    "# drops the row_number column since it is no longer needed. \n",
    "ncdata_80 = ncdata_80.drop(['row_number'],axis=1)\n",
    "ncdatarein = ncdata_80.reset_index()\n",
    "# #converts Date to datetime object\n",
    "ncdatarein['Date'] = pd.to_datetime(ncdatarein['Date'])\n",
    "alldatadf = ncdatarein.set_index('Date')\n",
    "alldatadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.572346Z",
     "start_time": "2019-07-31T20:01:41.556718Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alldatadf = alldatadf.drop(['Raleigh AP, NC', 'Greensboro, NC', ' WILMINGTON 7 N, NC','LUMBERTON, NC','MYRTLE BEACH, SC','CHARLOTTE DOUGLAS AIRPORT, NC','GRNVL SPART INTL AP, SC','PICKENS, SC',' MT. MITCHELL, NC',' Caesars Head Area, SC'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12\n",
    "\n",
    "Providing distance data from all locations to all other locations using LAT/LONG coordinates. First, the functionto calculate distance between two points on the globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.587969Z",
     "start_time": "2019-07-31T20:01:41.572346Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1    \n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    return 2 * 6371 * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.681717Z",
     "start_time": "2019-07-31T20:01:41.587969Z"
    }
   },
   "outputs": [],
   "source": [
    "latlong = pd.read_csv('latlong.csv')\n",
    "latlongsplit = latlong.iloc[0].apply(str.split, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:01:41.697339Z",
     "start_time": "2019-07-31T20:01:41.681717Z"
    }
   },
   "outputs": [],
   "source": [
    "latlongdf = pd.DataFrame(latlongsplit)\n",
    "latlongdf = latlongdf.drop(['Unnamed: 0','Raleigh AP, NC', 'Greensboro, NC', ' WILMINGTON 7 N, NC','LUMBERTON, NC','MYRTLE BEACH, SC','CHARLOTTE DOUGLAS AIRPORT, NC','GRNVL SPART INTL AP, SC','PICKENS, SC',' MT. MITCHELL, NC',' Caesars Head Area, SC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:04.402005Z",
     "start_time": "2019-07-31T20:01:41.697339Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def distance_loc(df):\n",
    "    didf = pd.DataFrame(columns=df.index)\n",
    "    row = {}\n",
    "    for index in df.index:\n",
    "        lat1, long1 = float(df.loc[index][0][0]), float(df.loc[index][0][1])\n",
    "        for i in df.index:\n",
    "            lat2, long2 = float(df.loc[i][0][0]), float(df.loc[i][0][1])\n",
    "            dist = haversine(long1, lat1, long2, lat2)\n",
    "            row[i] = dist\n",
    "        didf = didf.append(row, ignore_index=True)\n",
    "    return(didf)\n",
    "distdf = distance_loc(latlongdf)\n",
    "distdf.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:04.417629Z",
     "start_time": "2019-07-31T20:02:04.402005Z"
    }
   },
   "outputs": [],
   "source": [
    "distdf2 = distdf\n",
    "distdf2.index = distdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:04.480254Z",
     "start_time": "2019-07-31T20:02:04.417629Z"
    }
   },
   "outputs": [],
   "source": [
    "distdf2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:11.793441Z",
     "start_time": "2019-07-31T20:02:04.480254Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# args: rdf = rain dataframe\n",
    "#       ddf = distance df\n",
    "\n",
    "def missingfillsurrounding(rdf, ddf):\n",
    "    locwmd = rdf.columns[rdf.isna().any()].tolist()\n",
    "    for loc in locwmd:\n",
    "        nbloc = rdf[ddf[[loc]][ddf[loc] <=85].index]\n",
    "        missing = nbloc.index[nbloc[loc].isnull()]\n",
    "        if len(missing) >0:\n",
    "            for m in missing:\n",
    "                newpt = np.nanmean(nbloc.loc[m])\n",
    "                rdf.loc[m,loc] = newpt\n",
    "    return(rdf)\n",
    "alldatadf_filled = missingfillsurrounding(alldatadf, distdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:11.840311Z",
     "start_time": "2019-07-31T20:02:11.793441Z"
    }
   },
   "outputs": [],
   "source": [
    "locations = alldatadf_filled.columns\n",
    "ncloc = locations[locations.str.endswith('NC')]\n",
    "valoc = locations[locations.str.endswith('VA')]\n",
    "scloc = locations[locations.str.endswith('SC')]\n",
    "galoc = locations[locations.str.endswith('GA')]\n",
    "tnloc = locations[locations.str.endswith('TN')]\n",
    "ncdatadf = alldatadf_filled[ncloc]\n",
    "vadatadf = alldatadf_filled[valoc]\n",
    "scdatadf = alldatadf_filled[scloc]\n",
    "gadatadf = alldatadf_filled[galoc]\n",
    "tndatadf = alldatadf_filled[tnloc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:12.856034Z",
     "start_time": "2019-07-31T20:02:11.840311Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alldatadf_filled.to_csv('rainfalldata.csv')\n",
    "distdf2.to_csv('distances.csv')\n",
    "ncdatadf.to_csv('ncrainfalldata.csv')\n",
    "vadatadf.to_csv('varainfalldata.csv')\n",
    "scdatadf.to_csv('scrainfalldata.csv')\n",
    "gadatadf.to_csv('garainfalldata.csv')\n",
    "tndatadf.to_csv('tnrainfalldata.csv')\n",
    "ncdatadf['Raleigh, NC'].to_csv('raleighrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:12.887282Z",
     "start_time": "2019-07-31T20:02:12.856034Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of target locations = tarloc\n",
    "# list of exo locations = exoloc\n",
    "# latitude, longitude df = lldf\n",
    "def exofind(lldf, tarloc, exoloc):\n",
    "    tarexoloc = tarloc.append(exoloc)\n",
    "    tarexoll = lldf.loc[tarexoloc]\n",
    "    tartoexodist = distance_loc(tarexoll)\n",
    "    exodistances = tartoexodist[exoloc]\n",
    "    exodistances.index = tartoexodist.columns\n",
    "    exodist2 = exodistances.drop(exoloc,axis=0)\n",
    "    closeexo = exodist2[exodist2 <= 50]\n",
    "    closeexo1 = closeexo.dropna(how='all')\n",
    "    closeexo2 = closeexo1.dropna(axis=1,how='all')\n",
    "    exo = {}\n",
    "    for i in closeexo2.index:\n",
    "        ex = closeexo2.loc[i][closeexo2.loc[i].notnull()].index.tolist()\n",
    "        exo[i]=ex\n",
    "    return(exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:12.902907Z",
     "start_time": "2019-07-31T20:02:12.887282Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distdf2.loc[['CHESNEE 7 WSW, SC', 'CHESTER 1 SE, SC', 'GAFFNEY 6 E, SC', 'LOCKHART, SC'],' MOUNT HOLLY 4 NE, NC'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:12.934156Z",
     "start_time": "2019-07-31T20:02:12.902907Z"
    }
   },
   "outputs": [],
   "source": [
    "distdf2.loc[['CHESTERFIELD 3 E, SC',\n",
    "  ' CHERAW, SC',\n",
    "  'PAGELAND 9.0 WNW, SC',\n",
    "  'FORT MILL 4 NW, SC'],'Albemarle, NC'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:35.357593Z",
     "start_time": "2019-07-31T20:02:12.934156Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exoloc = valoc.append(scloc)\n",
    "exoloc = exoloc.append(galoc)\n",
    "exoloc = exoloc.append(tnloc)\n",
    "exogen = exofind(latlongdf,ncloc,exoloc)\n",
    "exogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:35.373223Z",
     "start_time": "2019-07-31T20:02:35.357593Z"
    }
   },
   "outputs": [],
   "source": [
    "l_val = []\n",
    "for key,value in exogen.items():\n",
    "    l_val.append(len(value))\n",
    "print(np.mean(l_val),max(l_val), len(exogen.keys()), np.sum(l_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:35.455685Z",
     "start_time": "2019-07-31T20:02:35.373223Z"
    }
   },
   "outputs": [],
   "source": [
    "%store exogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-31T20:02:35.674430Z",
     "start_time": "2019-07-31T20:02:35.455685Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations\n",
    "def exog_combinations_len(exoe):\n",
    "    lo_dfs = []\n",
    "    if len(exoe) == 1:\n",
    "        lo_dfs.append(1)\n",
    "    if len(exoe) > 1:\n",
    "        lo_dfs.append(1)\n",
    "        for ex in exoe:\n",
    "            lo_dfs.append(1)\n",
    "        if len(exoe) >2:\n",
    "            for i in range(2, len(exoe)):\n",
    "                combolist = list(combinations(exoe,i))\n",
    "                for c in combolist:\n",
    "                    lo_dfs.append(1)\n",
    "    return(lo_dfs)\n",
    "l_val2 =[]\n",
    "for key,value in tqdm(exogen.items()):\n",
    "    lolo = exog_combinations_len(value)\n",
    "    l_val2.append(len(lolo))\n",
    "np.sum(l_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 571.61666,
   "position": {
    "height": "40px",
    "left": "1197.6px",
    "right": "20px",
    "top": "120px",
    "width": "307.767px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
